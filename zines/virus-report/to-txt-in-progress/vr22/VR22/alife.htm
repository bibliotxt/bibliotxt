

<HTML>
<HEAD>
  <META NAME="GENERATOR" CONTENT="Trhuchedit 2.0 DOS">
  <TITLE>Hormigas lógicas y algoritmos genéticos </TITLE>
</HEAD>
<BODY BGCOLOR="#0080ff">

<H1><CENTER>Hormigas lógicas y algoritmos genéticos <BR>
por Martín Salías </CENTER></H1>
                     <BR><BR>






Un ensayo periodístico sobre uno de los campos
científicos más novedosos, convulsivos y extravagantes.
El mito de Frankestein revivido a través de un
micorprocesador y un puñado de ecuaciones.

<BR><BR>
Steven Levy, el autor de Hackers (comentado en esta misma
columna un par de meses atrás), ha realizado otro trabajo
de investigación periodística y narración épica. Esta vez
los primigenios hackers son reemplazados por los pioneros
de un nuevo campo científico, la Vida Artificial.
El objeto de estudio de estos investigadores, es vairado,
y más aún lo son sus motivos y sus puntos de vista. Levy
hace un recorrido por todos ellos en forma casi
histórica, comenzando por el padre intelectual de la
criatura, John von Neumann, el científico alemán que
emigrara a los Estados Unidos durante la segunda guerra
para sentar allí las bases de varias disciplinas, entre
ellas, la de la teoría de autómatas, y las primeras ideas
sobre organismos artificiales, hablando de máquinas
autoreproductoras y diseñando modelos teóricos que
serivirían de base a un sinúmero de variaciones. Como
parte de la multitud de proyectos que emprendió para la
NASA, Von Neumann estableció un modelo de fábricas
autoreplicantes que siguiendo reglas específicas,
buscarían y procesarían los materiales necesario para
producir vástagos.<BR><BR>
Las teorías de Von Neumann, y los demás fundadores de la
vida artificial se fundamentan, además, en la
demostración de Turing de que una máquina de estados
finitos (una computadora universal), independientemente
del tiempo, podría simular cualquier proceso. Partiendo
de la premisa de que la vida en sí es sólo un proceso
físico (en contra de las antiguas teorías vitalistas, que
sostenían la existencia de un 'flujo vital'), es obvia la
conclusión de que la vvida puede ser emulada por medias
mecánicos.<BR><BR>
Y la historia se retrotrare a algunos pocos ejemplos
anteriores, no del todo comprobados, como el ganso de
Vaucanson, un animal mecánico que asombró a las cortes
europeas en el siglo dieciocho por sus capacidades
metábolicas de comer, moverse, sacudir las plumas, y
finalmente, defecar.<BR><BR>
Pero la historia contemporánea comienza con los primeros
autómatas celulares, basados en las teorías de von
Neumann y las matemáticas de los juegos. El caso más
resonante, y que atrapó la atención de muchos, fue el
famoso LIFE de John Conway.<BR><BR>
LIFE es un juego de autómatas celulares fabuloso por su
sencillez y por el impacto que provoca ver pasar las
generaciones de células desarrollandose, adquiriendo
comportamientos tan específicos que inevitablemente no
lleva a verlos como 'naturales'. Su popularidad llegó
hasta tal punto que es muy común conseguir programas de
LIFE (por ejemplo, entre las demos del Quick-C).
Las reglas, para los que quieran probar, son sencillas.
Según las palabras del creador:<BR><BR>
"La vida transcurre en un damero virtual. Los cuadros son
llamados células. Estas están en uno de dos estados:
vivas o muertas. Cada célula tiene ocho vecinos posibles,
las células que tocan su lados o sus esquinas.
Si una célula del damero está viva, sobrevivirá en el
siguiente período de tiempo (o generación) si dos o tres
de sus vecinos también están vivos. Morirá de
aplastamiento si tiene más de tres vecinos vivos, y
morirá de abandono si tiene menos de dos.
Si una célula del damero está muerta, permanecerá muerta
en la próxima generación salvo que exactamente tres de
sus ocho vecinos están vivos. En ese caso, la célula
'nacerá' en la próxima generación."

<BR><BR>
A partir de allí surgieron varios aficionados a la teoría
de autómatas celulares (entre ellos el Dr.E.F.Codd,
creador del modelo de bases de datos relacionales), y
montones de experiencias comenzaron a realizarse, aunque
sólo fuera en el ghetto de la matemática. Entre otros,
Levy describe con detalle las experiencias de Toffolli,
Margolus, Wolfram y sus autómatas unidimensionales,
Packard y sus copos de nieve,  los boids de Reynolds,
diseñados para simular el comportamiento de los pájaros
al formar bandadas.<BR><BR>
Estos experimentos, sin ninguna aplicación específica y
de connotaciones dudosas para el resto del ámbito
académico, llevó a los investigadores a proseguirlos
básicamente por propia iniciativa, utilizando muchas
veces medios caseros, o recursos derivados de su campo
principal (su actividad 'seria'). Levy llama a esto
bandas de garage científicas, y sus principales
representantes son Doyn Farmer, Chris Langton (quién
generó una clase de autómatas celulares en forma de rulo
en su Apple II), el mismo Codd, y otros más que se
reunieron bajo el nombe de Grupo de Lógica Informática.
Todos estos fanáticos de los Sistemas Complejos luchaban
por los mismo: conseguir que sus autómatas tuvieran
comportamiento emergente, es decir, no programado
específicamente.   <BR><BR>
En esto ayudó mucho el uso de redes neuronales sencillas
como 'motores' de las reglas de comportamiento de los
autómatas. De hecho, en el transcurso de experiencias de
este tipo salieron a la luz ciertas tendencias de los
sistemas a ordenarse sólos en base a ciertas reglas
mínimas.<BR><BR>
Pero para poder mutar e interactuar correctamente, los
autómatas debían sofisticarse más aún. Varios modelos
utilizaron 'criaturas' formadas por información pura,
instrucciones de algún tipo de lenguaje intermedio que
pudiese se fácilmente controlado y estudiado. Muchos de
estos modelos se basan en el set de instrucciones del
CoreWar (el juego del Corewar fue objeto de un campeonato
en los primeros números de Virus Report).<BR><BR>
Lo que empezó a surgir a esta altura es mayor
acercamiento a la biología real. En la reproducción
biológica hay dos componentes principales: un genotipo,
que contiene codificadas las características del
individuo, y un fenotipo, que codifica el mecanismo de la
reproducción misma. La insistencia en este tipo de
tendencias llevaría al punto más interesante, la
posibilidad de evolución de estos organismos. Para esto
comenzarían a aplicarse las ideas de John Holland, un
teórico de la informática que por haberse desarrollado
científicamente antes de la revolución de las
microcomputadoras, había tenido pocas oportunidades de
ponerlas en práctica. Su mayor aporte a esta causa en
especial fue la invención de los algoritmos genéticos.
Los algoritmos genéticos se basan en la genética
biológica. En esta, varios factores permiten la
evolución. Uno de ellos, el más célebre, es la mutación.
Cuando una cadena de ADN es copiada a otra en el proceso
reproductivo, uno de los nucleotidos (los eslabones de
una cadena de ADN), puede cambiar por uno de otro tipo,
produciéndo una diferencia mínima o trascendental. La
selección natural se encargará del resto, favoreciendo al
organismo más apto con mayor descendencia sobre el menos
apto, con menores probabilidades. Sin embargo, otro
factor, menos conocido, también incide sobre la
evolución, y es el entrecruzamiento que se produce en la
reproducción sexual entre los genes del padre y la madre.
Este cruce minúsculo da lugar a una diversidad
formidable, y aunque fue en general minimizado por la
biología tradicional, los experimentos de los a-lifers
parecen indicar que en realidad es un factor clave,
muchísimo más importante para la evolución que la
mutación, que es, de hecho, un fenómeno muy infrecuente.
Y aquí aparece uno de los puntos más interesantes de este
campo de estudio, y es la posibilidad de estudiar la
evolución a través de la producción de miles de
generaciones en un lapso de tiempo accesible al ser
humano, cuando en la vida orgánica esto se hace
prácticamente imposible.<BR><BR>
Así, los investigadores lograron reproducir verdadero
comportamiento emergentes similares a los de insectos en
sus criaturas a través de muchas generaciones
reproduciéndose y evolucionando en base a ciento tipo de
reglas que determinan la mayor o menor aptitud para
sobrevivir.<BR><BR>
El siguiente paso hacia adelante sería la posibilidad de
utilizar procesadores paralelos para emular el
comportamiento de las criaturas, y así poder dotar a cada
individuo de su propio 'sistema nervioso', comenzando así
a investigar el comportamiento colectivo, y la evolución
en conjunto de especies en lugar de limitarse a
individuos.<BR><BR>
El libro se extiende en muchos de los casos y da
explicaciones sencillas pero suficientemente detalladas
como para dejar claros cada uno de los métodos y sirve
como guía introductoria para comenzar a desarrollar ideas
y pruebas propias.<BR><BR>
Más adelante, Levy nos habla de la 'verdadera vida
artificial', la que es producida en el grupo MOBOT (de
robots móviles) del MIT. Allí, un grupo de científicos
aplican las teorías y algoritmos de autómatas celulares y
otro organismos artificiales en criaturas mecánicas. Los
mecanismos básicos y las pautas de comportamiento y
aprendizaje de éstos son analizados en detalle.
Y finalmente, el libro llega a la más exitosa de las
formas de vida artificial, la que más profusamente se ha
esparcido, a pesar de haber surgido de un medio mucho
menos científico y con una teoría menos erudita como
fundamento: los virus informáticos. En este punto los
lectores de esta revista probablemente encontrarán más
obvias las explicaciones, peor es intersante ver como los
virus son analizados con el marco de referencia anterior,
y algunos de los planteos filosóficos a los que se
llegan, los que son, claro, un punto de partida para
discusiones interminables.<BR><BR>
Resumiendo, el libro es muy interesante y muy claro, y
nos despierta muchas inquietudes. Se exponen muchos
métodos y se nos sugieren muchas ideas acerca del futuro
de la vida artificial, y por supuesto, el de los virus.
<BR><BR>


</BODY>
</HTML>
